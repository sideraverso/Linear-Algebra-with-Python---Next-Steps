{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "criminal-spyware",
   "metadata": {},
   "source": [
    "# Linear Algebra with Python: Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-calculator",
   "metadata": {},
   "source": [
    "## Linear Algebra & NumPy Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-dimension",
   "metadata": {},
   "source": [
    "Linear algebra is the branch of mathematics dealing with linear equations and their representations in vector spaces and through matrices. Much of machine learning is built on top of linear algebra making it an important skill for data scientists to know.\n",
    "\n",
    "We'll focus on some of the most useful tools in linear algebra for machine learning, and how to implement them with NumPy, but we'll first start out some review of the basics!\n",
    "\n",
    "First, some helpful notation:\n",
    " - By $A_{m \\times n}$ we denote a matrix $A$ with m rows and n columns.\n",
    " - By $\\vec{x}$ in $\\mathbb{R}^n$, we denote a vector with n entries. By convention, an n-dimensional vector is often thought of as a matrix with n rows and 1 column, known as a column vector:\n",
    " \n",
    " $$\\vec{x} = \\begin{pmatrix}x_1\\\\ x_2\\\\ ... \\\\ x_n\\end{pmatrix}$$\n"
   ]
  },
  {
   "attachments": {
    "28cd2cbb-fe6a-485d-b903-776fa8709c0e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "certain-poverty",
   "metadata": {},
   "source": [
    "<h4>Vectors and matrices (and their relevance in ML)</h4>\n",
    "\n",
    "Recall a vector, $\\vec{x}$ in $\\mathbb{R}^n$. In practice vectors usually have two main interpretations\n",
    "    \n",
    "      1. A list of n numbers or a collection\n",
    "      2. Location and direction in n-dimensional space.\n",
    "    \n",
    "For example, the vector $\\vec{x} = \\begin{pmatrix}1\\\\1\\end{pmatrix}$ could represent two items in a list, or could be represented by the position and direction shown by the red arrow in the graph below.\n",
    "    \n",
    "![image.png](attachment:28cd2cbb-fe6a-485d-b903-776fa8709c0e.png) \n",
    "\n",
    "\n",
    "We will mostly focus on the numerical interpretation of vectors, but it is often intereasting and helpful to think about their geometric interpretations. In particular, we will focus on some of the interpretations of linear algebra that are directly related to machine learning.\n",
    "\n",
    "Recall the ideas behind supervised[1] machine learning: you have inputs $x_1, x_2, ..., x_n$ with labels $y_1, y_2, ..., y_n$, then you are trying to find patterns in the data to predict the labels for new inputs. A very convenient way to represent this as a system of linear equations where you have a matrix $X_{nxd}$ of all your x values:\n",
    "\n",
    "$$ \\mathbf{X} = \\begin{pmatrix}x_{0,0} & x_{0,1} & ... & x_{0,d}\\\\x_{1,0} & x_{1,1} & ... & x_{1,d}\\\\  &  & ... & \\\\x_{n,0} & x_{n,1} & ... & x_{n,d}\\end{pmatrix} $$\n",
    "\n",
    "And an n-dimensional vector $y \\in \\mathbb{R}^n$:\n",
    "\n",
    "$$\\vec{y} = \\begin{pmatrix}y_1\\\\ y_2\\\\ ... \\\\ y_n\\end{pmatrix}$$\n",
    "\n",
    "Then we want to find a $d \\times 1$ vector $\\beta$ that <i>best</i> represents the relationship between x and y:\n",
    "\n",
    "$$ \\vec{\\beta} = \\begin{pmatrix}\\beta_0 & \\beta_1 & ... & \\beta_d\\end{pmatrix} $$\n",
    "\n",
    "This ends up giving us the system of equations $\\mathbf{X}\\vec{\\beta} = \\vec{y}$:\n",
    "\n",
    "$$\\begin{pmatrix}x_{0,0} & x_{0,1} & ... & x_{0,d}\\\\x_{1,0} & x_{1,1} & ... & x_{1,d}\\\\  &  & ... & \\\\x_{n,0} & x_{n,1} & ... & x_{n,d}\\end{pmatrix} \\begin{pmatrix}\\beta_0 & \\beta_1 & ... & \\beta_d\\end{pmatrix} =\\begin{pmatrix}y_1\\\\ y_2\\\\ ... \\\\ y_n\\end{pmatrix}$$\n",
    "\n",
    "In order to understand and work with this system of equations, we will review matrix multiplication, dot products, and how to use numpy to find them!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h6>[1] If you are new to machine learning, supervised means ... TODO</h6>"
   ]
  },
  {
   "attachments": {
    "c3d2ae58-07bd-446d-a2d2-d5e313b0a558.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "gentle-tragedy",
   "metadata": {},
   "source": [
    "<h4>Matrix multiplication</h4>\n",
    "\n",
    "Geometrically, we can think of matrix multiplication as \n",
    "\n",
    "Practically, when we are dealing with a system of equations $A\\vec{x} = \\vec{y}$, it is useful \n",
    "\n",
    "When dealing with systems of equations, or wanting to find Matrix multiplication between two matrices X and Y, expressed in NumPy as $X@Y$ or <i>np.matmul(X,Y)</i> works as follows:\n",
    "\n",
    "![image.png](attachment:c3d2ae58-07bd-446d-a2d2-d5e313b0a558.png)\n",
    "\n",
    "\n",
    "Recall that the dimensions must line up - ${M}_{n \\times m}, {N}_{m \\times p} \\rightarrow M1M2_{n \\times p}$\n",
    "Which means that matrix multiplication is not commutative, for example: \n",
    "\n",
    "$$\\mathbf{M} = \\begin{pmatrix}2 & 4 & 6\\\\3 & 5 & 7\\end{pmatrix}\\qquad\n",
    "\\mathbf{N} = \\begin{pmatrix}1 & 2 & 3\\\\ 4 & 5 & 6\\\\7 & 8 & 9\\end{pmatrix}$$\n",
    "$\\mathbf{MN}$ is defined, but $\\mathbf{NM}$ is not.\n",
    "\n",
    "Furthermore, if we take a look back at the system of equations defined by $\\mathbf{X}\\vec{\\beta} = \\vec{y}$, we can see that $\\mathbf{X}$ is a $n \\times d$-dimensional vector, and $\\beta$ is a $d \\times 1$-dimensional vector. Therefore, matrix multiplication is defined, and should output a $1 \\times n$-dimensional vector, which lines up with $\\vec{y}$'s dimensionality!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-semester",
   "metadata": {},
   "source": [
    "<h4>Dot Products</h4>\n",
    "Dot products are a special case of matrix multiplication. The dot product between two vectors of the same size, $\\vec{x} \\cdot \\vec{y}$, is found by the taking the sum of multiplying corresponding entries. i.e. for $\\vec{x} = \\begin{pmatrix}x_1 & x_2 & \\cdots & x_n\\end{pmatrix}$ and $ \\vec{y} = \\begin{pmatrix}y_1 & y_2 & \\cdots & y_n\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-therapist",
   "metadata": {},
   "source": [
    "$$\\vec{x} \\cdot \\vec{y} = x_1y_1 + x_2y_2 + \\cdots + x_ny_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-outreach",
   "metadata": {},
   "source": [
    "<b><u>Exercise<u></b> Implement the dot product between the two first using python code, then using NumPy. Note: NumPy has a great library for linear algebra which you can use here, and which we will be using throughout the course: https://numpy.org/doc/stable/reference/routines.linalg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_python(A, B):\n",
    "    # Write implentation using python here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_numpy(A, B):\n",
    "    # Write implementation using NumPy here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-garlic",
   "metadata": {},
   "source": [
    "Now, use your functions to find the dot product between the following vectors:\n",
    "\n",
    "$$A_1=\\begin{pmatrix}2\\\\4\\\\1\\\\7\\\\4\\end{pmatrix} \\qquad B_1=\\begin{pmatrix}1\\\\9\\\\0\\\\0\\\\1\\end{pmatrix}$$. \n",
    "\n",
    "$$A_2=[1]^{100} \\qquad B_2=[2]^{100}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 2 µs, total: 33 µs\n",
      "Wall time: 36 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "A1 = [2,4,1,7,4]\n",
    "B1 = [1,9,0,0,1]\n",
    "\n",
    "A2 = [1] * 100\n",
    "B2 = [2] * 100\n",
    "\n",
    "dot_product_python(A1, B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "single-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95 µs, sys: 5 µs, total: 100 µs\n",
      "Wall time: 104 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "A = np.array([2,4,1,7,4])\n",
    "B = np.array([1,9,0,0,1])\n",
    "\n",
    "A2 = np.ones(100)\n",
    "B2 = np.ones(100) * 2\n",
    "\n",
    "dot_product_numpy(A1, B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-catering",
   "metadata": {},
   "source": [
    "Notice how much more efficient numpy arrays are, <i>and</i> how much easier it is to find a dot product. What else does NumPy make easier? Lots!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-walker",
   "metadata": {},
   "source": [
    "<b><u>Exercise</u></b> Using NumPy do the following:\n",
    "\n",
    "    1. Find MN\n",
    "    2. show that NM is not defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ruled-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[2,4,6],[3,5,7]])\n",
    "N = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "# find MN\n",
    "\n",
    "# show what happens when you try to multiply NM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-marking",
   "metadata": {},
   "source": [
    "## Special Types of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-reset",
   "metadata": {},
   "source": [
    "<b><u>Identity Matrix</u></b>: Identity matrices are square matrices with ones along the diagonal, and zeros everywhere else. The $n \\times n$ identity matrix is the <i>multiplicative identity</i> for matrices in $\\mathbb{R}^n$. Essentially, it does the same thing that the number 1 does with scalar multiplication in $\\mathbb{R}$. Essentially, for $A_{nxn}$ we have that  $AI = IA = A$. For example:\n",
    "\n",
    "$$\\begin{pmatrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{pmatrix} \\begin{pmatrix}1 & 0 & 0\\\\ 0 & 1 & 0\\\\0 & 0 & 1\\end{pmatrix} = \\begin{pmatrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{pmatrix}$$\n",
    "\n",
    "Furthermore, $I_{nxn}$ is the multiplicative inverse of any matrix for which matrix multiplication is defined. If we have $B_{dxn}$, then $BI=B$, and if we have $C_{nxd}$, then $IC = C.$ \n",
    "\n",
    "<b><u>Inverse Matrix</u></b>: Another important application of inverse matrices comes up when we define inverse matrices. The inverse of a matrix is defined as $A^{-1}$ such that $AA^{-1} = A^{-1}A = I$. Note that not all matrices have inverses. Non-square matrices, for example, do not have inverses by definition. However, for some square matrices $A$, it may still be the case that $A^{-1}$ may not exist. The quick way to check for invertibility is to find the determinant of a matrix. For $n \\times n$ matrix $A$, if $det(A) = 0$, then the matrix is not invertible. Otherwise $A$ is invertible. We can use NumPy to help us figure this out, and to find the inverse of a matrix! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-russian",
   "metadata": {},
   "source": [
    "<b>Exercise:</b> Find the determinant of the matrices A, B, C and D defined below. If the determinant $\\neq 0$, find it's inverse. Then verify that the product of a matrix and it's inverse is the identity. With NumPy, you can use np.eye(n) to produce $I_{n \\times n}$. (Useful reference: https://numpy.org/doc/stable/reference/routines.linalg.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "progressive-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[0,1,4],[5,6,0]])\n",
    "\n",
    "B = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "C = np.array([[6,-1,-1],[-1,6,-1],[-1,-1,1]])\n",
    "\n",
    "D = np.array([[-2,4],[1,-3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-going",
   "metadata": {},
   "source": [
    "<b><u>Diagonal Matrix</u></b> Diagonal matrices are square matrices which have entries along the diagonal and zeros everywhere else. Diagonal matrices are nice to work with because:\n",
    "\n",
    "1. Their eigenvalues and eigenvectors are known (will cover this in later section)\n",
    "2. Raising diagonal matrices to a power is equivalent to raising each of it's diagonal entries to that power. Instead of multiplying out a matrix p times, you can just computer scalars to a power instead:\n",
    "\n",
    "$$\\begin{pmatrix}\\ x_1 & 0 & 0\\\\0 & x_2 & 0\\\\0 & 0 & x_3\\end{pmatrix} \\times \\begin{pmatrix}\\ x_1 & 0 & 0\\\\0 & x_2 & 0\\\\0 & 0 & x_3\\end{pmatrix} \\times ... \\times \\begin{pmatrix}\\ x_1 & 0 & 0\\\\0 & x_2 & 0\\\\0 & 0 & x_3\\end{pmatrix} = \\begin{pmatrix}\\ (x_1)^p & 0 & 0\\\\0 & (x_2)^p & 0\\\\0 & 0 & (x_3)^p\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-athens",
   "metadata": {},
   "source": [
    "## Inner Products and Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-wheel",
   "metadata": {},
   "source": [
    "Inner product is another term for dot product, and in this section we will further explore the importance of finding the inner product between vectors and normalizing vectors. Consider the supervised machine learning scenario presented earlier, where you have n entries of d-dimensional feature vectors represented as $X$, n labels for those feature vectors, $\\vec{y},$ and the *best* $\\vec{\\beta}$ that represents the relationship between $X$ and $\\vec{y}$. This is a very general model, and there are many different algorithms that fall under the umbrella of 'supervised machine learning.' But they all beg the question of what does *best* mean in this context. In general, *best* means the value for $\\beta$ which minimizes the error when predicting $\\vec{y}$. The way we typically find this prediction error is by finding the norm of $X\\vec{\\beta} - \\vec{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-suicide",
   "metadata": {},
   "source": [
    "The <b><u>norm</u></b> of a vector informally represents the 'length' of a vector. For example, the $\\ell_2$-norm (a.k.a the Euclidean norm) is the square root of the dot product of a vector with itself, represented as $\\|\\vec{x}\\|$:\n",
    "\n",
    "$$\\|\\vec{x}\\| = \\sqrt{x_0^2 + x_1^2 + \\cdots + x_n^2}$$\n",
    "\n",
    "Similarly, there are other types of norms, $\\ell_1$-norm which finds returns the sum of the absolute value of each entry, and the $\\ell_{\\infty}$-norm, which just returns the maximum of the absolute value of each entry of a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-trading",
   "metadata": {},
   "source": [
    "<b><u>Exercise</u></b> find the $\\ell_1$-norm, $\\ell_2$-norm and $\\ell_{\\infty}$-norm of the following vectors:\n",
    "\n",
    "$$\\vec{a} = \\begin{pmatrix}\\ 4\\\\-2\\\\-7\\\\3\\end{pmatrix} \\qquad \\vec{b} = \\begin{pmatrix}\\ 1\\\\1\\\\1\\\\1\\\\1\\end{pmatrix} \\qquad \\vec{c} = \\begin{pmatrix}\\ 100\\\\10\\\\0\\\\-10\\\\-100\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indian-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([4,-2,7,3])\n",
    "b = np.array([1,1,1,1,1])\n",
    "c = np.array([100,10,0,-10,-100])\n",
    "\n",
    "# Using numpy or computations, find l_1, l_2, l_inf norms of a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-authentication",
   "metadata": {},
   "source": [
    "<b><u>Orthogonal Vectors</u></b>: Orthogonal means perpindicular, so if two vectors are orthogonal then they are perpindicular to one another. Computationally, two vectors are orthogonal if $\\vec{x} \\cdot \\vec{y} = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-speaking",
   "metadata": {},
   "source": [
    "<b><u>Exercise</u></b>: Determine which of the following pairs of vectors are orthogonal.\n",
    "    \n",
    "$$\\vec{a}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\\vec{b}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}$$\n",
    "\n",
    "$$\\vec{c}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix},\\vec{d}=\\begin{pmatrix}5\\\\2\\\\0\\end{pmatrix}$$\n",
    "\n",
    "$$\\vec{e}=\\begin{pmatrix}1\\\\-1\\\\0\\end{pmatrix},\\vec{f}=\\begin{pmatrix}-1\\\\1\\\\0\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "funky-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,0,0])\n",
    "b = np.array([0,1,0])\n",
    "c = np.array([1,1,1])\n",
    "d = np.array([5,2,0])\n",
    "e = np.array([1,-1,0])\n",
    "f = np.array([-1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-apartment",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-support",
   "metadata": {},
   "source": [
    "Eigen in German means characteristic, so *eigenvector* means characteristic vector. In order to get a better understanding of what this means, it's useful to return back to our geometric interpretation of linear algebra. Just as we could think of vectors as location and direction, we can think of matrices as linear transformations, where matrix-vector multiplication transforrms a vector. With this idea in mind, we can define $\\lambda$ as the <b>eigenvalue</b> for a matrix $A$ for corresponding <b>eigenvector</b> $\\vec{x}$ such that $A\\vec{x} = \\lambda\\vec{x}$. Intuitively, this definition means that multiplying $A$ by the vector $\\vec{x}$ results in a new vector that points in the same direction as $\\vec{x}$, but scaled by a factor $\\lambda$. You can only find eigenvalues and eigenvectors for square matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-ordering",
   "metadata": {},
   "source": [
    "<b><u>Exercise</u></b> Using numpy, find the eigenvalues of the following matrices:\n",
    "\n",
    "$$J = \\begin{pmatrix}\\ 2 & 2 & 2\\\\2 & 2 & 2\\\\2 & 2 & 2\\end{pmatrix} \\qquad K = \\begin{pmatrix}\\ 1 & 2 & 3\\\\0 & 4 & 5\\\\0 & 0 & 6\\end{pmatrix} \\qquad L = \\begin{pmatrix}\\ 0 & 0 & 1\\\\0 & 2 & 0\\\\3 & 0 & 0\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-marriage",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-midwest",
   "metadata": {},
   "source": [
    "Since we can only decompose square matrices into eigenvalues and eigenvectors, we turn to <b>singular value decomposition</b> to decompose non-square $m \\times n$-dimensional matrices. In very simplified terms, SVD is just decompos;ing vectors onto orthogonal (perpindicular) axes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-symposium",
   "metadata": {},
   "source": [
    "<b><u>Exercise</u></b> Using SVD in NumPy, decompose the following matrix:\n",
    "\n",
    "$$J = \\begin{pmatrix}\\ 1 & 2\\\\0 & 1\\\\2 & -1\\end{pmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
